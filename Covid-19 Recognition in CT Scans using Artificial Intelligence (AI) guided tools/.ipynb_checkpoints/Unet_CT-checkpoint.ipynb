{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import cv2                 \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import glob as gb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.models import custom_unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the dataset path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read DataSet\n",
    "Image_Directory =\"./Dataset/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get all image names in train file\n",
    "Healthy_images = os.listdir(Image_Directory + \"/Healthy_images\")\n",
    "Covid_images = os.listdir(Image_Directory + \"/Covid_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels={'Covid_images':0,'Healthy_images':1 }\n",
    "\n",
    "#convert label to code\n",
    "def getCode(label):\n",
    "    return Labels[label]\n",
    "\n",
    "#convert code to label \n",
    "def getLabel(n):\n",
    "    for x,c in Labels.items():\n",
    "        if n==c:\n",
    "            return x\n",
    "               \n",
    "#Test        \n",
    "print(getCode('Covid_images'))\n",
    "print(getLabel(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading image data\n",
    "sizeImage=224 # to resize the all image as same size\n",
    "\n",
    "#to read all images from directory\n",
    "def getData(Dir,sizeImage):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for folder in  os.listdir(Dir) : #to get the file name \n",
    "        files = gb.glob(pathname= str( Dir  +\"/\" +folder+ '//*.png' )) #to get the images\n",
    "        for file in files:\n",
    "                picture=cv2.imread(file)\n",
    "                imageArray=cv2.resize(picture,(sizeImage,sizeImage))\n",
    "                X.append(list(imageArray))\n",
    "                y.append(getCode(folder))\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train data\n",
    "X, y = getData(TrainImage,sizeImage)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"X_train Shape        \",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert y_train to categorical\n",
    "y_train=to_categorical(y_train,2)\n",
    "print(\"y_train \",y_train.shape)\n",
    "\n",
    "#Convert y_train to categorical\n",
    "y_test=to_categorical(y_test,2)\n",
    "print(\"y_test \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      samplewise_center=True,\n",
    "      samplewise_std_normalization= True,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load weight\n",
    "Network_Weight=\"./unet.h5\"\n",
    "print(Network_Weight)\n",
    "\n",
    "pre_trained_model = custom_unet(input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Flatten()(pre_trained_model.output)\n",
    "\n",
    "#Full Connected Layers\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "#Add dropout to avoid Overfit\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "#Add dropout to avoid Overfit\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "x=tf.keras.layers.Dense(2 , activation='sigmoid')(x)   \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold Cross Validation model evaluation\n",
    "num_folds = 5\n",
    "fold_no = 1\n",
    "epochs = 10\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor='accuracy', factor=0.1, min_delta=0.0001, patience=1, verbose=1)\n",
    "\n",
    "filepath=\"uuuche.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_list = []\n",
    "\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    \n",
    "    train_generator =train_datagen.flow(\n",
    "         X_train[train], y_train[train],\n",
    "         batch_size= 256\n",
    "    )\n",
    "\n",
    "    test_generator =train_datagen.flow(\n",
    "         X_train[test], y_train[test],\n",
    "         batch_size= 50\n",
    "    )  \n",
    "\n",
    "    history = model.fit(train_generator,steps_per_epoch=20,callbacks=[lr_reduce,checkpoint],\n",
    "             epochs=epochs)\n",
    "\n",
    "    scores = model.evaluate(test_generator)\n",
    "    score_list.append(scores)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; {model.metrics_names[2]} of {scores[2]}')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in score_list:\n",
    "    print(s[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator =train_datagen.flow(\n",
    "     X_test, y_test,\n",
    "     batch_size= 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evaluate Model\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pred \\n\",len(pred))\n",
    "print(\"y_test \\n\",len(y_test))\n",
    "\n",
    "print(\"y_test \\n\",y_test)\n",
    "print(\"pred \\n\",pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
