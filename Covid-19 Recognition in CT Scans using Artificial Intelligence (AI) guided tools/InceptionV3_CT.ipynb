{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import cv2                 \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import glob as gb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, AveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the dataset path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read DataSet\n",
    "Image_Directory = \"./Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get all image names in train file\n",
    "Healthy_images = os.listdir(Image_Directory + \"/Healthy_images\")\n",
    "Covid_images = os.listdir(Image_Directory + \"/Covid_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels={'Covid_images':0,'Healthy_images':1 }\n",
    "\n",
    "#convert label to code\n",
    "def getCode(label):\n",
    "    return Labels[label]\n",
    "\n",
    "#convert code to label \n",
    "def getLabel(n):\n",
    "    for x,c in Labels.items():\n",
    "        if n==c:\n",
    "            return x\n",
    "               \n",
    "#Test        \n",
    "print(getCode('Covid_images'))\n",
    "print(getLabel(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeImage=224 # to resize the all image as same size\n",
    "\n",
    "#to read all images from directory\n",
    "def getData(Dir,sizeImage):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for folder in  os.listdir(Dir) : #to get the file name \n",
    "        files = gb.glob(pathname= str( Dir  +\"/\" +folder+ '//*.png' )) #to get the images\n",
    "        for file in files:\n",
    "                picture=cv2.imread(file)\n",
    "                imageArray=cv2.resize(picture,(sizeImage,sizeImage))\n",
    "                X.append(list(imageArray))\n",
    "                y.append(getCode(folder))\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train data\n",
    "X, y = getData(Image_Directory,sizeImage)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"X_train Shape        \",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert y_train to categorical\n",
    "y_train=to_categorical(y_train,2)\n",
    "print(\"y_train \",y_train.shape)\n",
    "\n",
    "#Convert y_train to categorical\n",
    "y_test=to_categorical(y_test,2)\n",
    "print(\"y_test \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = InceptionV3(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "outputs = pre_trained_model.output\n",
    "outputs = Flatten(name=\"flatten\")(outputs)\n",
    "outputs = Dropout(0.5)(outputs)\n",
    "outputs = Dense(2, activation=\"softmax\")(outputs)\n",
    "\n",
    "model = Model(inputs=pre_trained_model.input, outputs=outputs)\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer='adam', \n",
    "        metrics=['accuracy', \n",
    "                 tf.keras.metrics.AUC(name='auc'), \n",
    "                 tf.keras.metrics.Precision(name='precision'), \n",
    "                        tf.keras.metrics.Recall(name='recall')]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold Cross Validation model evaluation\n",
    "num_folds = 5\n",
    "fold_no = 1\n",
    "epochs = 20\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor='accuracy', factor=0.1, min_delta=0.0001, patience=1, verbose=1)\n",
    "\n",
    "filepath=\"inc.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_list = []\n",
    "\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    \n",
    "    train_generator =train_datagen.flow(\n",
    "         X_train[train], y_train[train],\n",
    "         batch_size= 256\n",
    "    )\n",
    "\n",
    "    test_generator =train_datagen.flow(\n",
    "         X_train[test], y_train[test],\n",
    "         batch_size= 50\n",
    "    )  \n",
    "\n",
    "    history = model.fit(train_generator,steps_per_epoch=50,callbacks=[lr_reduce,checkpoint],\n",
    "                        validation_data=(X_test, y_test),\n",
    "                    validation_steps=len(X_test) / 32,\n",
    "             epochs=epochs)\n",
    "\n",
    "    scores = model.evaluate(test_generator)\n",
    "    score_list.append(scores)\n",
    "\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; {model.metrics_names[2]} of {scores[2]}; {model.metrics_names[3]} of {scores[3]}; {model.metrics_names[4]} of {scores[4]}')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in score_list:\n",
    "    print(s[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator =train_datagen.flow(\n",
    "     X_test, y_test,\n",
    "     batch_size= 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evaluate Model\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "y_pred_bin = np.argmax(y_pred, axis=1)\n",
    "y_test_bin = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_bin, y_pred_bin)\n",
    "plt.plot(fpr, tpr,linewidth=2)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for our model')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)\n",
    "plt.savefig('inception_roc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_confusion_matrix(normalize):\n",
    "    classes = ['Covid_images','Healthy_images']\n",
    "    tick_marks = [0.5,1.5]\n",
    "    cn = confusion_matrix(y_test_bin, y_pred_bin,normalize=normalize)\n",
    "    sns.heatmap(cn,cmap=plt.cm.Blues,annot=True)\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "print('Confusion Matrix without Normalization')\n",
    "plot_confusion_matrix(normalize=None)\n",
    "\n",
    "print('Confusion Matrix with Normalized Values')\n",
    "plot_confusion_matrix(normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_bin, y_pred_bin))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
