{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#So now lets import our training and test datasets\ntrain=pd.read_csv('../input/titanic/train.csv')\ntest=pd.read_csv('../input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets check the count of null values in our training dataset\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assign y as survived column from training dataset\ny=train['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cabin column is really intresting and can be quite usefull so we wont be deleting it and we'll replace the null values by any letter in\n#this case consider U and we will fill the null values for both train and test data\n\ntrain[\"Cabin\"].unique()\ntrain[\"Cabin\"] = train[\"Cabin\"].fillna('U')\ntrain[\"Cabin\"] = train[\"Cabin\"].apply(lambda x: x[0])\n\n\ntest[\"Cabin\"].unique()\ntest[\"Cabin\"] = test[\"Cabin\"].fillna('U')\ntest[\"Cabin\"] = test[\"Cabin\"].apply(lambda x: x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets make us new column Family size which will give us the total number of family size for every passenger  \ntrain['FamilySize'] = train['SibSp'] + train['Parch'] + 1\ntest['FamilySize'] = test['SibSp'] + test['Parch'] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Name list contains the title which can be very usefull for survival prediction ,so we will extract the title from evey name and remove \n#the remaining data\n\ntrain['Name'] = train['Name'].map(lambda x: x.split(',')[1].split('.')[0].strip())\ntitles = train['Name'].unique()\n\ntest['Name'] = test['Name'].map(lambda x: x.split(',')[1].split('.')[0].strip())\ntitles1 = test['Name'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titles,titles1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #Feature Encoding by using Get dummies.You can use one hot encoding as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Name Column\ntitle_train=pd.get_dummies(train['Name'],drop_first=True,prefix='Title')\ntrain=pd.concat([train,title_train],axis=1)\ntrain.drop(columns=['Name'],axis=1,inplace=True)\n\ntitle_test=pd.get_dummies(test['Name'],drop_first=True,prefix='Title')\ntest=pd.concat([test,title_test],axis=1)\ntest.drop(columns=['Name'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sibsp Column\nSib_train=pd.get_dummies(train['SibSp'],drop_first=True,prefix='Sib')\ntrain=pd.concat([train,Sib_train],axis=1)\ntrain.drop(columns=['SibSp'],axis=1,inplace=True)\n\nSib_test=pd.get_dummies(test['SibSp'],drop_first=True,prefix='Sib')\ntest=pd.concat([test,Sib_test],axis=1)\ntest.drop(columns=['SibSp'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cabin Column\ncabin_train=pd.get_dummies(train['Cabin'],drop_first=True,prefix='Cabin')\ntrain=pd.concat([train,cabin_train],axis=1)\ntrain.drop(columns=['Cabin'],axis=1,inplace=True)\n\ncabin_test=pd.get_dummies(test['Cabin'],drop_first=True,prefix='Cabin')\ntest=pd.concat([test,cabin_test],axis=1)\ntest.drop(columns=['Cabin'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Parch Column\nparch_train=pd.get_dummies(train['Parch'],drop_first=True,prefix='Parch')\ntrain=pd.concat([train,parch_train],axis=1)\ntrain.drop(columns=['Parch'],axis=1,inplace=True)\n\nparch_test=pd.get_dummies(test['Parch'],drop_first=True,prefix='Parch')\ntest=pd.concat([test,parch_test],axis=1)\ntest.drop(columns=['Parch'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Age.min(),train.Age.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As we can see above the value of Age column ranges from 0.42 to 80.0.So we will create a new column Age Attributes that will \n#define the attribute of person by their age\n#1) For training data:-\ncondition_train=[\n    (train.Age<10),\n    (train.Age<20),\n    (train.Age<50),\n    (train.Age<80)\n    \n]\n\nAge_attributes_train=['minor','teenage','Adult','Old']\n\ntrain['Age_attributes']=np.select(condition_train,Age_attributes_train,default='Ages')\n\n#2) For testing data:-\ncondition_test=[\n    (test.Age<10),\n    (test.Age<20),\n    (test.Age<50),\n    (test.Age<80)\n    \n]\nAge_attributes_test=['minor','teenage','Adult','Old']\n\ntest['Age_attributes']=np.select(condition_test,Age_attributes_test,default='Ages')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we will drop the age column as we've created a new column of Age Attributes\ntrain.drop(columns=['Age'],axis=1,inplace=True)\ntest.drop(columns=['Age'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum(),   test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Encoding Continues:\nAge_train=pd.get_dummies(train['Age_attributes'],drop_first=True,prefix='Ages_of_people')\nAge_test=pd.get_dummies(test['Age_attributes'],drop_first=True,prefix='Ages_of_people')\n\ntrain=pd.concat([train,Age_train],axis=1)\ntest=pd.concat([test,Age_test],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdclass_train=pd.get_dummies(train['Pclass'],drop_first=True,prefix='Class')\npdclass_test=pd.get_dummies(test['Pclass'],drop_first=True,prefix='Class')\ntrain=pd.concat([train,pdclass_train],axis=1)\ntest=pd.concat([test,pdclass_test],axis=1)\ntrain.drop(columns=['Pclass'],axis=1,inplace=True)\ntest.drop(columns=['Pclass'],axis=1,inplace=True)\nsex=pd.get_dummies(train['Sex'],drop_first=True,prefix='Sex')\nsex1=pd.get_dummies(test['Sex'],drop_first=True,prefix='Sex')\nEmbarked=pd.get_dummies(train['Embarked'],drop_first=True,prefix='Embarked')\nEmbarked1=pd.get_dummies(test['Embarked'],drop_first=True,prefix='Embarked')\ntest=pd.concat([test,sex1,Embarked1],axis=1)\ntrain=pd.concat([train,sex,Embarked],axis=1)\ntrain.drop(columns=['Sex','Embarked'],axis=1,inplace=True)  \ntest.drop(columns=['Sex','Embarked'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We'll drop the age attributes now as we've created dummy variables for it\ntrain.drop(columns=['Age_attributes'],axis=1,inplace=True)\ntest.drop(columns=['Age_attributes'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Firstly we'll have to drop Parch_9 column from test dataset as this column doesnt exist in training data\ntest.drop(columns=['Parch_9'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Fare'].fillna(test['Fare'].mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We wont be needing Ticket column as it has lot of unique values and feature encoding wont be possible, so we'll just dropit\ntrain.drop(columns=['Ticket'],axis=1,inplace=True)\ntest.drop(columns=['Ticket'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#From the title column we've created we have a lot of new colums from train set that aren' present in test set\n#so we will delete those columns from our train dataset\ntrain.drop(columns=['Title_Mlle','Title_Col','Title_the Countess','Title_Jonkheer','Title_Major','Title_Lady','Title_Mlle','Title_Mme','Title_Sir'],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cabin_T is also an extra colun in train set which isnt present in test set so we will drop that as well\ntrain.drop(columns=['Cabin_T'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.rename(columns={'Title_Dona':'Title_Don'},inplace=True)\ntrain.drop(columns=['Survived'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Alright our both datasets are ready\n#We'll just take a look at their shape\ntrain.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This is he model that worked best for me and got me good accuracy\n#You can use it as well  :)\nleaderboard_model = RandomForestClassifier(criterion='gini',\n                                           n_estimators=1750,\n                                           max_depth=7,\n                                           min_samples_split=6,\n                                           min_samples_leaf=6,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           random_state=None,\n                                           n_jobs=-1,\n                                           verbose=1)\nleaderboard_model.fit(train,y)\nleaderboard_model.score(train,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#0.85 now thats a great accuracy for a begineer\n#Make sure to carefully follow the steps throghout to get this accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=leaderboard_model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gendercsv=pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':y_pred})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gendercsv.to_csv('gender.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Thats it guys thanks for sticking throghout\n#Bye for now","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
